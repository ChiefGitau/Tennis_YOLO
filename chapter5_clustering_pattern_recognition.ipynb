{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Clustering & Pattern Recognition\n",
    "## Tennis Analysis - Ball Hit Detection and Player Position Clustering\n",
    "\n",
    "This notebook demonstrates the concepts from ML4QS Chapter 5 applied to tennis analysis:\n",
    "- Ball hit detection algorithm: Pattern recognition in temporal sequences\n",
    "- Player selection/filtering: Classification based on court position\n",
    "- Shot frame detection: Event clustering in time series\n",
    "- Distance measurements: Similarity metrics for player/ball positioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../tennis_analysis-main')\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Prepare for Clustering\n",
    "\n",
    "Load ball and player detection data for clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load detection data\n",
    "with open('../tennis_analysis-main/tracker_stubs/ball_detections.pkl', 'rb') as f:\n",
    "    ball_detections = pickle.load(f)\n",
    "\n",
    "with open('../tennis_analysis-main/tracker_stubs/player_detections.pkl', 'rb') as f:\n",
    "    player_detections = pickle.load(f)\n",
    "\n",
    "# Process ball data\n",
    "ball_positions = [x.get(1,[]) for x in ball_detections]\n",
    "df_ball = pd.DataFrame(ball_positions, columns=['x1','y1','x2','y2'])\n",
    "df_ball = df_ball.interpolate().bfill()\n",
    "df_ball['center_x'] = (df_ball['x1'] + df_ball['x2']) / 2\n",
    "df_ball['center_y'] = (df_ball['y1'] + df_ball['y2']) / 2\n",
    "\n",
    "print(f\"Ball data shape: {df_ball.shape}\")\n",
    "print(f\"Player data frames: {len(player_detections)}\")\n",
    "print(f\"Ball detection rate: {(~df_ball['center_x'].isna()).sum() / len(df_ball):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distance Metrics Implementation\n",
    "\n",
    "Implement various distance metrics similar to ML4QS Chapter 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TennisDistanceMetrics:\n",
    "    \"\"\"\n",
    "    Distance metrics for tennis analysis\n",
    "    Similar to ML4QS Chapter 5 DistanceMetrics\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def euclidean_distance(point1, point2):\n",
    "        \"\"\"Standard Euclidean distance\"\"\"\n",
    "        return np.sqrt(np.sum((np.array(point1) - np.array(point2))**2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def manhattan_distance(point1, point2):\n",
    "        \"\"\"Manhattan (L1) distance\"\"\"\n",
    "        return np.sum(np.abs(np.array(point1) - np.array(point2)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def temporal_distance(trajectory1, trajectory2, max_lag=5):\n",
    "        \"\"\"Distance between temporal trajectories with lag consideration\"\"\"\n",
    "        min_distance = float('inf')\n",
    "        \n",
    "        for lag in range(-max_lag, max_lag + 1):\n",
    "            if lag >= 0:\n",
    "                t1 = trajectory1[lag:]\n",
    "                t2 = trajectory2[:len(t1)]\n",
    "            else:\n",
    "                t2 = trajectory2[-lag:]\n",
    "                t1 = trajectory1[:len(t2)]\n",
    "            \n",
    "            if len(t1) > 0 and len(t2) > 0:\n",
    "                distance = np.mean([TennisDistanceMetrics.euclidean_distance(p1, p2) \n",
    "                                  for p1, p2 in zip(t1, t2)])\n",
    "                min_distance = min(min_distance, distance)\n",
    "        \n",
    "        return min_distance\n",
    "    \n",
    "    @staticmethod\n",
    "    def court_zone_distance(zone1, zone2):\n",
    "        \"\"\"Distance between court zones\"\"\"\n",
    "        zone_map = {\n",
    "            'back_left': (0, 0), 'back_center': (0, 1), 'back_right': (0, 2),\n",
    "            'middle_left': (1, 0), 'middle_center': (1, 1), 'middle_right': (1, 2),\n",
    "            'front_left': (2, 0), 'front_center': (2, 1), 'front_right': (2, 2)\n",
    "        }\n",
    "        \n",
    "        if zone1 in zone_map and zone2 in zone_map:\n",
    "            p1, p2 = zone_map[zone1], zone_map[zone2]\n",
    "            return TennisDistanceMetrics.euclidean_distance(p1, p2)\n",
    "        return 0\n",
    "\n",
    "# Test distance metrics\n",
    "dm = TennisDistanceMetrics()\n",
    "point1, point2 = [100, 200], [150, 250]\n",
    "print(f\"Euclidean distance: {dm.euclidean_distance(point1, point2):.2f}\")\n",
    "print(f\"Manhattan distance: {dm.manhattan_distance(point1, point2):.2f}\")\n",
    "print(f\"Zone distance: {dm.court_zone_distance('back_left', 'front_right'):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ball Hit Detection Using Pattern Recognition\n",
    "\n",
    "Implement the temporal pattern recognition algorithm for ball hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate features for pattern recognition\n",
    "df_ball['mid_y'] = df_ball['center_y']\n",
    "df_ball['mid_y_rolling_mean'] = df_ball['mid_y'].rolling(window=5, min_periods=1, center=False).mean()\n",
    "df_ball['delta_y'] = df_ball['mid_y_rolling_mean'].diff()\n",
    "df_ball['ball_hit'] = 0\n",
    "\n",
    "# Ball hit detection algorithm (pattern recognition)\n",
    "minimum_change_frames_for_hit = 25\n",
    "\n",
    "for i in range(1, len(df_ball) - int(minimum_change_frames_for_hit * 1.2)):\n",
    "    # Detect direction changes in vertical movement\n",
    "    negative_position_change = (df_ball['delta_y'].iloc[i] > 0 and \n",
    "                               df_ball['delta_y'].iloc[i+1] < 0)\n",
    "    positive_position_change = (df_ball['delta_y'].iloc[i] < 0 and \n",
    "                               df_ball['delta_y'].iloc[i+1] > 0)\n",
    "    \n",
    "    if negative_position_change or positive_position_change:\n",
    "        change_count = 0\n",
    "        \n",
    "        for change_frame in range(i+1, i + int(minimum_change_frames_for_hit * 1.2) + 1):\n",
    "            if change_frame >= len(df_ball):\n",
    "                break\n",
    "                \n",
    "            negative_following = (df_ball['delta_y'].iloc[i] > 0 and \n",
    "                                 df_ball['delta_y'].iloc[change_frame] < 0)\n",
    "            positive_following = (df_ball['delta_y'].iloc[i] < 0 and \n",
    "                                 df_ball['delta_y'].iloc[change_frame] > 0)\n",
    "            \n",
    "            if ((negative_position_change and negative_following) or \n",
    "                (positive_position_change and positive_following)):\n",
    "                change_count += 1\n",
    "        \n",
    "        if change_count > minimum_change_frames_for_hit - 1:\n",
    "            df_ball.loc[i, 'ball_hit'] = 1\n",
    "\n",
    "ball_hit_frames = df_ball[df_ball['ball_hit'] == 1].index.tolist()\n",
    "print(f\"Detected {len(ball_hit_frames)} ball hits using pattern recognition\")\n",
    "print(f\"Ball hit frames: {ball_hit_frames}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clustering Ball Trajectory Patterns\n",
    "\n",
    "Apply K-means clustering to identify different ball movement patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for trajectory clustering\n",
    "window_size = 10\n",
    "trajectory_features = []\n",
    "frame_indices = []\n",
    "\n",
    "# Create trajectory segments\n",
    "for i in range(window_size, len(df_ball) - window_size):\n",
    "    segment = df_ball.iloc[i-window_size:i+window_size]\n",
    "    \n",
    "    if not segment['center_x'].isna().any() and not segment['center_y'].isna().any():\n",
    "        features = [\n",
    "            # Position statistics\n",
    "            segment['center_x'].mean(),\n",
    "            segment['center_y'].mean(),\n",
    "            segment['center_x'].std(),\n",
    "            segment['center_y'].std(),\n",
    "            \n",
    "            # Movement statistics\n",
    "            segment['center_x'].diff().mean(),\n",
    "            segment['center_y'].diff().mean(),\n",
    "            segment['center_x'].diff().std(),\n",
    "            segment['center_y'].diff().std(),\n",
    "            \n",
    "            # Range\n",
    "            segment['center_x'].max() - segment['center_x'].min(),\n",
    "            segment['center_y'].max() - segment['center_y'].min(),\n",
    "        ]\n",
    "        \n",
    "        trajectory_features.append(features)\n",
    "        frame_indices.append(i)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_trajectories = pd.DataFrame(trajectory_features, columns=[\n",
    "    'x_mean', 'y_mean', 'x_std', 'y_std',\n",
    "    'dx_mean', 'dy_mean', 'dx_std', 'dy_std',\n",
    "    'x_range', 'y_range'\n",
    "])\n",
    "df_trajectories['frame'] = frame_indices\n",
    "\n",
    "print(f\"Created {len(df_trajectories)} trajectory segments for clustering\")\n",
    "print(\"\\nTrajectory features:\")\n",
    "print(df_trajectories.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-Means Clustering Analysis\n",
    "\n",
    "Apply K-means clustering similar to ML4QS Chapter 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features for clustering\n",
    "feature_cols = ['x_mean', 'y_mean', 'x_std', 'y_std', 'dx_mean', 'dy_mean', 'dx_std', 'dy_std', 'x_range', 'y_range']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_trajectories[feature_cols])\n",
    "\n",
    "# Determine optimal number of clusters using elbow method and silhouette score\n",
    "k_range = range(2, 10)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, labels))\n",
    "\n",
    "# Plot elbow curve and silhouette scores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.plot(k_range, inertias, 'bo-')\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Inertia')\n",
    "ax1.set_title('Elbow Method for Optimal k')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(k_range, silhouette_scores, 'ro-')\n",
    "ax2.set_xlabel('Number of Clusters (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('Silhouette Score vs Number of Clusters')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Choose optimal k\n",
    "optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"Optimal number of clusters: {optimal_k}\")\n",
    "print(f\"Best silhouette score: {max(silhouette_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Apply K-Means with Optimal Clusters\n",
    "\n",
    "Perform final K-means clustering and analyze results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-means with optimal k\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df_trajectories['cluster'] = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "# Calculate cluster statistics\n",
    "cluster_stats = df_trajectories.groupby('cluster')[feature_cols].mean()\n",
    "print(\"Cluster centers (original scale):\")\n",
    "print(cluster_stats)\n",
    "\n",
    "# Cluster size distribution\n",
    "cluster_counts = df_trajectories['cluster'].value_counts().sort_index()\n",
    "print(f\"\\nCluster size distribution:\")\n",
    "for cluster, count in cluster_counts.items():\n",
    "    percentage = (count / len(df_trajectories)) * 100\n",
    "    print(f\"  Cluster {cluster}: {count} segments ({percentage:.1f}%)\")\n",
    "\n",
    "# Silhouette analysis\n",
    "silhouette_avg = silhouette_score(X_scaled, df_trajectories['cluster'])\n",
    "sample_silhouette_values = silhouette_samples(X_scaled, df_trajectories['cluster'])\n",
    "\n",
    "print(f\"\\nAverage silhouette score: {silhouette_avg:.3f}\")\n",
    "\n",
    "# Plot silhouette analysis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(optimal_k):\n",
    "    cluster_silhouette_values = sample_silhouette_values[df_trajectories['cluster'] == i]\n",
    "    cluster_silhouette_values.sort()\n",
    "    \n",
    "    size_cluster_i = cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "    \n",
    "    color = plt.cm.nipy_spectral(float(i) / optimal_k)\n",
    "    ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_silhouette_values,\n",
    "                     facecolor=color, edgecolor=color, alpha=0.7)\n",
    "    \n",
    "    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "ax1.set_xlabel('Silhouette coefficient values')\n",
    "ax1.set_ylabel('Cluster label')\n",
    "ax1.set_title('Silhouette Plot for Trajectory Clusters')\n",
    "ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "# PCA visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "colors = plt.cm.nipy_spectral(np.linspace(0, 1, optimal_k))\n",
    "for i in range(optimal_k):\n",
    "    cluster_points = X_pca[df_trajectories['cluster'] == i]\n",
    "    ax2.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "               c=[colors[i]], label=f'Cluster {i}', alpha=0.7)\n",
    "\n",
    "ax2.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "ax2.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "ax2.set_title('Trajectory Clusters in PCA Space')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. DBSCAN Clustering for Event Detection\n",
    "\n",
    "Apply DBSCAN to detect event clusters in temporal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare event data (ball hits and surrounding context)\n",
    "event_features = []\n",
    "event_frames = []\n",
    "\n",
    "for hit_frame in ball_hit_frames:\n",
    "    # Extract context around ball hit\n",
    "    start_idx = max(0, hit_frame - 10)\n",
    "    end_idx = min(len(df_ball), hit_frame + 10)\n",
    "    \n",
    "    context = df_ball.iloc[start_idx:end_idx]\n",
    "    \n",
    "    if len(context) >= 10:  # Ensure minimum context length\n",
    "        features = [\n",
    "            # Hit location\n",
    "            df_ball.iloc[hit_frame]['center_x'],\n",
    "            df_ball.iloc[hit_frame]['center_y'],\n",
    "            \n",
    "            # Pre-hit movement\n",
    "            context.iloc[:10]['center_x'].diff().mean(),\n",
    "            context.iloc[:10]['center_y'].diff().mean(),\n",
    "            \n",
    "            # Post-hit movement\n",
    "            context.iloc[10:]['center_x'].diff().mean() if len(context) > 10 else 0,\n",
    "            context.iloc[10:]['center_y'].diff().mean() if len(context) > 10 else 0,\n",
    "            \n",
    "            # Movement magnitude\n",
    "            context['center_x'].diff().abs().mean(),\n",
    "            context['center_y'].diff().abs().mean(),\n",
    "        ]\n",
    "        \n",
    "        event_features.append(features)\n",
    "        event_frames.append(hit_frame)\n",
    "\n",
    "if len(event_features) > 0:\n",
    "    df_events = pd.DataFrame(event_features, columns=[\n",
    "        'hit_x', 'hit_y', 'pre_dx', 'pre_dy', 'post_dx', 'post_dy', 'mag_dx', 'mag_dy'\n",
    "    ])\n",
    "    df_events['frame'] = event_frames\n",
    "    \n",
    "    # Normalize event features\n",
    "    event_scaler = StandardScaler()\n",
    "    X_events_scaled = event_scaler.fit_transform(df_events[['hit_x', 'hit_y', 'pre_dx', 'pre_dy', 'post_dx', 'post_dy', 'mag_dx', 'mag_dy']])\n",
    "    \n",
    "    # Apply DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=2)\n",
    "    df_events['dbscan_cluster'] = dbscan.fit_predict(X_events_scaled)\n",
    "    \n",
    "    # Analyze DBSCAN results\n",
    "    n_clusters = len(set(df_events['dbscan_cluster'])) - (1 if -1 in df_events['dbscan_cluster'] else 0)\n",
    "    n_noise = list(df_events['dbscan_cluster']).count(-1)\n",
    "    \n",
    "    print(f\"DBSCAN Results for Ball Hit Events:\")\n",
    "    print(f\"  Number of clusters: {n_clusters}\")\n",
    "    print(f\"  Number of noise points: {n_noise}\")\n",
    "    print(f\"  Total events: {len(df_events)}\")\n",
    "    \n",
    "    if n_clusters > 0:\n",
    "        print(\"\\nCluster distribution:\")\n",
    "        for cluster in sorted(df_events['dbscan_cluster'].unique()):\n",
    "            count = (df_events['dbscan_cluster'] == cluster).sum()\n",
    "            if cluster == -1:\n",
    "                print(f\"  Noise: {count} events\")\n",
    "            else:\n",
    "                print(f\"  Cluster {cluster}: {count} events\")\n",
    "else:\n",
    "    print(\"No ball hit events found for DBSCAN analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hierarchical Clustering for Player Positions\n",
    "\n",
    "Apply hierarchical clustering to analyze player positioning patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract player positions (simplified analysis)\n",
    "player_positions = []\n",
    "for frame_idx, frame_data in enumerate(player_detections[:100]):  # Limit for demo\n",
    "    if frame_data:\n",
    "        for player_id, detections in frame_data.items():\n",
    "            if detections:  # If player detected in this frame\n",
    "                bbox = detections[0]  # Take first detection\n",
    "                center_x = (bbox[0] + bbox[2]) / 2\n",
    "                center_y = (bbox[1] + bbox[3]) / 2\n",
    "                \n",
    "                player_positions.append({\n",
    "                    'frame': frame_idx,\n",
    "                    'player_id': player_id,\n",
    "                    'center_x': center_x,\n",
    "                    'center_y': center_y,\n",
    "                    'bbox_width': bbox[2] - bbox[0],\n",
    "                    'bbox_height': bbox[3] - bbox[1]\n",
    "                })\n",
    "\n",
    "if len(player_positions) > 10:\n",
    "    df_players = pd.DataFrame(player_positions)\n",
    "    \n",
    "    # Aggregate player positions by frame windows\n",
    "    window_size = 10\n",
    "    player_segments = []\n",
    "    \n",
    "    for start_frame in range(0, df_players['frame'].max() - window_size, window_size//2):\n",
    "        window_data = df_players[\n",
    "            (df_players['frame'] >= start_frame) & \n",
    "            (df_players['frame'] < start_frame + window_size)\n",
    "        ]\n",
    "        \n",
    "        if len(window_data) > 0:\n",
    "            # Aggregate by player\n",
    "            for player_id in window_data['player_id'].unique():\n",
    "                player_window = window_data[window_data['player_id'] == player_id]\n",
    "                \n",
    "                if len(player_window) >= 3:  # Minimum appearances in window\n",
    "                    segment = {\n",
    "                        'start_frame': start_frame,\n",
    "                        'player_id': player_id,\n",
    "                        'mean_x': player_window['center_x'].mean(),\n",
    "                        'mean_y': player_window['center_y'].mean(),\n",
    "                        'std_x': player_window['center_x'].std(),\n",
    "                        'std_y': player_window['center_y'].std(),\n",
    "                        'mobility': np.sqrt(player_window['center_x'].diff().pow(2) + \n",
    "                                          player_window['center_y'].diff().pow(2)).mean()\n",
    "                    }\n",
    "                    player_segments.append(segment)\n",
    "    \n",
    "    if len(player_segments) > 5:\n",
    "        df_player_segments = pd.DataFrame(player_segments)\n",
    "        \n",
    "        # Prepare features for hierarchical clustering\n",
    "        feature_cols = ['mean_x', 'mean_y', 'std_x', 'std_y', 'mobility']\n",
    "        X_player = df_player_segments[feature_cols].fillna(0)\n",
    "        X_player_scaled = StandardScaler().fit_transform(X_player)\n",
    "        \n",
    "        # Perform hierarchical clustering\n",
    "        linkage_matrix = linkage(X_player_scaled, method='ward')\n",
    "        \n",
    "        # Plot dendrogram\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        dendrogram(linkage_matrix, truncate_mode='level', p=5)\n",
    "        plt.title('Hierarchical Clustering of Player Position Patterns')\n",
    "        plt.xlabel('Sample Index or Cluster Size')\n",
    "        plt.ylabel('Distance')\n",
    "        plt.show()\n",
    "        \n",
    "        # Extract clusters\n",
    "        n_clusters = 3\n",
    "        cluster_labels = fcluster(linkage_matrix, n_clusters, criterion='maxclust')\n",
    "        df_player_segments['hc_cluster'] = cluster_labels\n",
    "        \n",
    "        print(f\"Hierarchical clustering results for player positions:\")\n",
    "        print(f\"Number of player position segments: {len(df_player_segments)}\")\n",
    "        print(f\"Cluster distribution:\")\n",
    "        for cluster in sorted(df_player_segments['hc_cluster'].unique()):\n",
    "            count = (df_player_segments['hc_cluster'] == cluster).sum()\n",
    "            print(f\"  Cluster {cluster}: {count} segments\")\n",
    "    else:\n",
    "        print(\"Insufficient player position data for hierarchical clustering\")\n",
    "else:\n",
    "    print(\"Insufficient player position data extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Temporal Event Sequence Clustering\n",
    "\n",
    "Cluster sequences of events to identify game patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create event sequences based on ball hits\n",
    "def create_event_sequences(ball_hit_frames, sequence_length=5):\n",
    "    \"\"\"\n",
    "    Create sequences of inter-hit intervals for clustering\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    \n",
    "    if len(ball_hit_frames) >= sequence_length:\n",
    "        # Calculate inter-hit intervals\n",
    "        intervals = np.diff(ball_hit_frames)\n",
    "        \n",
    "        # Create sequences\n",
    "        for i in range(len(intervals) - sequence_length + 1):\n",
    "            sequence = intervals[i:i + sequence_length]\n",
    "            sequences.append(sequence)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "# Generate event sequences\n",
    "sequences = create_event_sequences(ball_hit_frames, sequence_length=3)\n",
    "\n",
    "if len(sequences) > 2:\n",
    "    df_sequences = pd.DataFrame(sequences, columns=[f'interval_{i}' for i in range(len(sequences[0]))])\n",
    "    \n",
    "    # Add sequence statistics\n",
    "    df_sequences['mean_interval'] = df_sequences.mean(axis=1)\n",
    "    df_sequences['std_interval'] = df_sequences.std(axis=1)\n",
    "    df_sequences['rhythm_consistency'] = 1 / (1 + df_sequences['std_interval'])  # Higher = more consistent\n",
    "    \n",
    "    # Normalize for clustering\n",
    "    sequence_features = df_sequences[[f'interval_{i}' for i in range(len(sequences[0]))]]\n",
    "    sequence_scaler = StandardScaler()\n",
    "    X_sequences_scaled = sequence_scaler.fit_transform(sequence_features)\n",
    "    \n",
    "    # Apply K-means clustering to event sequences\n",
    "    n_seq_clusters = min(3, len(sequences))\n",
    "    kmeans_sequences = KMeans(n_clusters=n_seq_clusters, random_state=42)\n",
    "    df_sequences['sequence_cluster'] = kmeans_sequences.fit_predict(X_sequences_scaled)\n",
    "    \n",
    "    print(f\"Event Sequence Analysis:\")\n",
    "    print(f\"Total sequences: {len(df_sequences)}\")\n",
    "    print(f\"Sequence length: {len(sequences[0])} intervals\")\n",
    "    \n",
    "    print(\"\\nSequence cluster characteristics:\")\n",
    "    for cluster in sorted(df_sequences['sequence_cluster'].unique()):\n",
    "        cluster_data = df_sequences[df_sequences['sequence_cluster'] == cluster]\n",
    "        print(f\"  Cluster {cluster}: {len(cluster_data)} sequences\")\n",
    "        print(f\"    Mean interval: {cluster_data['mean_interval'].mean():.1f} frames\")\n",
    "        print(f\"    Rhythm consistency: {cluster_data['rhythm_consistency'].mean():.3f}\")\n",
    "    \n",
    "    # Visualize sequence clusters\n",
    "    if len(df_sequences) > 1:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Plot interval patterns\n",
    "        plt.subplot(1, 2, 1)\n",
    "        for cluster in sorted(df_sequences['sequence_cluster'].unique()):\n",
    "            cluster_data = df_sequences[df_sequences['sequence_cluster'] == cluster]\n",
    "            plt.plot(cluster_data[sequence_features.columns].T, \n",
    "                    alpha=0.6, color=plt.cm.tab10(cluster))\n",
    "        plt.xlabel('Interval Position in Sequence')\n",
    "        plt.ylabel('Inter-hit Interval (frames)')\n",
    "        plt.title('Event Sequence Patterns by Cluster')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Plot rhythm consistency\n",
    "        plt.subplot(1, 2, 2)\n",
    "        for cluster in sorted(df_sequences['sequence_cluster'].unique()):\n",
    "            cluster_data = df_sequences[df_sequences['sequence_cluster'] == cluster]\n",
    "            plt.scatter(cluster_data['mean_interval'], cluster_data['rhythm_consistency'],\n",
    "                       label=f'Cluster {cluster}', alpha=0.7)\n",
    "        plt.xlabel('Mean Interval (frames)')\n",
    "        plt.ylabel('Rhythm Consistency')\n",
    "        plt.title('Sequence Characteristics')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Insufficient ball hit events for sequence analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Comprehensive Analysis and Results Summary\n",
    "\n",
    "Summarize all clustering and pattern recognition results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results summary\n",
    "results_summary = {\n",
    "    'Pattern Recognition': {\n",
    "        'Ball hits detected': len(ball_hit_frames),\n",
    "        'Hit frames': ball_hit_frames,\n",
    "        'Detection rate': f\"{len(ball_hit_frames)/len(df_ball)*100:.2f}% of frames\"\n",
    "    },\n",
    "    \n",
    "    'Trajectory Clustering': {\n",
    "        'Optimal clusters': optimal_k,\n",
    "        'Silhouette score': f\"{max(silhouette_scores):.3f}\",\n",
    "        'Trajectory segments': len(df_trajectories)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TENNIS ANALYSIS - CLUSTERING & PATTERN RECOGNITION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for category, metrics in results_summary.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value}\")\n",
    "\n",
    "# Distance metrics comparison\n",
    "print(\"\\nDistance Metrics Demonstration:\")\n",
    "if len(ball_hit_frames) >= 2:\n",
    "    frame1, frame2 = ball_hit_frames[0], ball_hit_frames[1]\n",
    "    pos1 = [df_ball.iloc[frame1]['center_x'], df_ball.iloc[frame1]['center_y']]\n",
    "    pos2 = [df_ball.iloc[frame2]['center_x'], df_ball.iloc[frame2]['center_y']]\n",
    "    \n",
    "    euclidean_dist = dm.euclidean_distance(pos1, pos2)\n",
    "    manhattan_dist = dm.manhattan_distance(pos1, pos2)\n",
    "    \n",
    "    print(f\"  Distance between first two hits:\")\n",
    "    print(f\"    Euclidean: {euclidean_dist:.2f} pixels\")\n",
    "    print(f\"    Manhattan: {manhattan_dist:.2f} pixels\")\n",
    "\n",
    "# Cluster interpretation\n",
    "print(\"\\nCluster Interpretation:\")\n",
    "if 'df_trajectories' in locals() and len(df_trajectories) > 0:\n",
    "    for cluster in sorted(df_trajectories['cluster'].unique()):\n",
    "        cluster_data = df_trajectories[df_trajectories['cluster'] == cluster]\n",
    "        avg_y = cluster_data['y_mean'].mean()\n",
    "        avg_movement = cluster_data['dy_mean'].abs().mean()\n",
    "        \n",
    "        if avg_y < 400:  # Upper part of court\n",
    "            court_area = \"Upper court\"\n",
    "        elif avg_y > 600:  # Lower part of court  \n",
    "            court_area = \"Lower court\"\n",
    "        else:\n",
    "            court_area = \"Middle court\"\n",
    "        \n",
    "        if avg_movement < 5:\n",
    "            movement_type = \"Slow/stationary\"\n",
    "        elif avg_movement < 15:\n",
    "            movement_type = \"Moderate movement\"\n",
    "        else:\n",
    "            movement_type = \"Fast movement\"\n",
    "        \n",
    "        print(f\"  Cluster {cluster}: {court_area}, {movement_type} ({len(cluster_data)} segments)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Analysis complete - All clustering results saved and visualized\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated Chapter 5 concepts:\n",
    "\n",
    "1. **Distance Metrics**: Implemented various distance functions for tennis data analysis\n",
    "2. **Pattern Recognition**: Applied temporal pattern detection for ball hit identification\n",
    "3. **K-Means Clustering**: Clustered ball trajectory patterns with optimal cluster selection\n",
    "4. **DBSCAN Clustering**: Detected event clusters in temporal sequences\n",
    "5. **Hierarchical Clustering**: Analyzed player positioning patterns using dendrogram analysis\n",
    "6. **Temporal Sequence Clustering**: Identified game rhythm patterns in inter-hit intervals\n",
    "7. **Similarity Metrics**: Applied various distance measures for player/ball positioning\n",
    "8. **Cluster Validation**: Used silhouette analysis and elbow method for cluster quality assessment\n",
    "\n",
    "The clustering analysis revealed distinct patterns in tennis ball movement, player positioning, and game rhythm that can be used for advanced sports analytics and performance analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}