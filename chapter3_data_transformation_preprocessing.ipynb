{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Data Transformation & Preprocessing\n",
    "## Tennis Analysis - Missing Value Imputation and Data Smoothing\n",
    "\n",
    "This notebook demonstrates the concepts from ML4QS Chapter 3 applied to tennis analysis:\n",
    "- Missing value imputation using pandas interpolation\n",
    "- Rolling mean smoothing (equivalent to low-pass filtering)\n",
    "- Bounding box utilities: Data normalization and coordinate transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../tennis_analysis-main')\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "from utils.bbox_utils import get_center_of_bbox, measure_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Detection Data\n",
    "\n",
    "Load the ball detection data that contains missing values (similar to sensor data with gaps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ball detection data\n",
    "with open('../tennis_analysis-main/tracker_stubs/ball_detections.pkl', 'rb') as f:\n",
    "    ball_detections = pickle.load(f)\n",
    "\n",
    "# Extract ball positions\n",
    "ball_positions = [x.get(1,[]) for x in ball_detections]\n",
    "\n",
    "# Create DataFrame with missing values\n",
    "df_ball = pd.DataFrame(ball_positions, columns=['x1','y1','x2','y2'])\n",
    "\n",
    "print(f\"Total frames: {len(df_ball)}\")\n",
    "print(f\"Missing values per column:\")\n",
    "print(df_ball.isnull().sum())\n",
    "print(f\"\\nDetection rate: {(len(df_ball) - df_ball.isnull().any(axis=1).sum()) / len(df_ball):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Missing Value Imputation\n",
    "\n",
    "Apply interpolation techniques similar to ML4QS Chapter 3's imputation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show raw data with missing values\n",
    "print(\"Raw data (first 20 rows):\")\n",
    "print(df_ball.head(20))\n",
    "\n",
    "# Apply interpolation - equivalent to ImputationMissingValues.py\n",
    "df_ball_interpolated = df_ball.interpolate(method='linear')\n",
    "df_ball_interpolated = df_ball_interpolated.bfill()  # Backward fill for any remaining NaN\n",
    "\n",
    "print(\"\\nAfter interpolation:\")\n",
    "print(df_ball_interpolated.head(20))\n",
    "\n",
    "print(f\"\\nMissing values after interpolation:\")\n",
    "print(df_ball_interpolated.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Coordinate Transformations and Normalization\n",
    "\n",
    "Transform bounding box coordinates to center points and normalize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate center coordinates from bounding boxes\n",
    "df_ball_interpolated['center_x'] = (df_ball_interpolated['x1'] + df_ball_interpolated['x2']) / 2\n",
    "df_ball_interpolated['center_y'] = (df_ball_interpolated['y1'] + df_ball_interpolated['y2']) / 2\n",
    "\n",
    "# Calculate bounding box dimensions\n",
    "df_ball_interpolated['width'] = df_ball_interpolated['x2'] - df_ball_interpolated['x1']\n",
    "df_ball_interpolated['height'] = df_ball_interpolated['y2'] - df_ball_interpolated['y1']\n",
    "\n",
    "print(\"Coordinate transformations complete:\")\n",
    "print(df_ball_interpolated[['center_x', 'center_y', 'width', 'height']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Normalization\n",
    "\n",
    "Normalize coordinates to [0,1] range assuming video dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume video dimensions (typical HD video)\n",
    "VIDEO_WIDTH = 1920\n",
    "VIDEO_HEIGHT = 1080\n",
    "\n",
    "# Normalize coordinates\n",
    "df_ball_normalized = df_ball_interpolated.copy()\n",
    "df_ball_normalized['center_x_norm'] = df_ball_normalized['center_x'] / VIDEO_WIDTH\n",
    "df_ball_normalized['center_y_norm'] = df_ball_normalized['center_y'] / VIDEO_HEIGHT\n",
    "df_ball_normalized['width_norm'] = df_ball_normalized['width'] / VIDEO_WIDTH\n",
    "df_ball_normalized['height_norm'] = df_ball_normalized['height'] / VIDEO_HEIGHT\n",
    "\n",
    "print(\"Normalized coordinates (0-1 range):\")\n",
    "print(df_ball_normalized[['center_x_norm', 'center_y_norm', 'width_norm', 'height_norm']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Low-Pass Filtering (Rolling Mean Smoothing)\n",
    "\n",
    "Apply smoothing techniques equivalent to ML4QS Chapter 3's LowPassFilter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling mean smoothing (equivalent to low-pass filtering)\n",
    "window_size = 5\n",
    "df_ball_smoothed = df_ball_normalized.copy()\n",
    "\n",
    "# Apply rolling mean to center coordinates\n",
    "df_ball_smoothed['center_x_smooth'] = df_ball_smoothed['center_x'].rolling(window=window_size, min_periods=1, center=True).mean()\n",
    "df_ball_smoothed['center_y_smooth'] = df_ball_smoothed['center_y'].rolling(window=window_size, min_periods=1, center=True).mean()\n",
    "\n",
    "print(f\"Applied rolling mean with window size: {window_size}\")\n",
    "print(\"Smoothed coordinates:\")\n",
    "print(df_ball_smoothed[['center_x', 'center_x_smooth', 'center_y', 'center_y_smooth']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Butterworth Low-Pass Filter\n",
    "\n",
    "Apply actual low-pass filtering similar to ML4QS Chapter 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Butterworth low-pass filter\n",
    "def apply_lowpass_filter(data, sampling_freq=30, cutoff_freq=2, order=5):\n",
    "    \"\"\"\n",
    "    Apply Butterworth low-pass filter\n",
    "    sampling_freq: Video frame rate (30 fps)\n",
    "    cutoff_freq: Cutoff frequency in Hz\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * sampling_freq\n",
    "    normalized_cutoff = cutoff_freq / nyq\n",
    "    \n",
    "    b, a = butter(order, normalized_cutoff, btype='low', analog=False)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "# Apply low-pass filter to coordinates\n",
    "df_ball_smoothed['center_x_lowpass'] = apply_lowpass_filter(df_ball_smoothed['center_x'])\n",
    "df_ball_smoothed['center_y_lowpass'] = apply_lowpass_filter(df_ball_smoothed['center_y'])\n",
    "\n",
    "print(\"Applied Butterworth low-pass filter (cutoff: 2 Hz)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization of Preprocessing Effects\n",
    "\n",
    "Compare raw, interpolated, smoothed, and filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot preprocessing effects\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "frames = range(len(df_ball_smoothed))\n",
    "\n",
    "# X coordinate preprocessing\n",
    "ax1.plot(frames, df_ball['center_x'], 'r-', alpha=0.7, label='Raw (with gaps)', linewidth=1)\n",
    "ax1.plot(frames, df_ball_interpolated['center_x'], 'b-', alpha=0.8, label='Interpolated', linewidth=1)\n",
    "ax1.set_title('X Coordinate: Raw vs Interpolated')\n",
    "ax1.set_ylabel('X Position (pixels)')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Y coordinate preprocessing\n",
    "ax2.plot(frames, df_ball['center_y'], 'r-', alpha=0.7, label='Raw (with gaps)', linewidth=1)\n",
    "ax2.plot(frames, df_ball_interpolated['center_y'], 'b-', alpha=0.8, label='Interpolated', linewidth=1)\n",
    "ax2.set_title('Y Coordinate: Raw vs Interpolated')\n",
    "ax2.set_ylabel('Y Position (pixels)')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Smoothing comparison (X)\n",
    "ax3.plot(frames, df_ball_interpolated['center_x'], 'b-', alpha=0.5, label='Interpolated', linewidth=1)\n",
    "ax3.plot(frames, df_ball_smoothed['center_x_smooth'], 'g-', label='Rolling Mean', linewidth=2)\n",
    "ax3.plot(frames, df_ball_smoothed['center_x_lowpass'], 'orange', label='Low-pass Filter', linewidth=2)\n",
    "ax3.set_title('X Coordinate: Smoothing Comparison')\n",
    "ax3.set_ylabel('X Position (pixels)')\n",
    "ax3.set_xlabel('Frame')\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "\n",
    "# Smoothing comparison (Y)\n",
    "ax4.plot(frames, df_ball_interpolated['center_y'], 'b-', alpha=0.5, label='Interpolated', linewidth=1)\n",
    "ax4.plot(frames, df_ball_smoothed['center_y_smooth'], 'g-', label='Rolling Mean', linewidth=2)\n",
    "ax4.plot(frames, df_ball_smoothed['center_y_lowpass'], 'orange', label='Low-pass Filter', linewidth=2)\n",
    "ax4.set_title('Y Coordinate: Smoothing Comparison')\n",
    "ax4.set_ylabel('Y Position (pixels)')\n",
    "ax4.set_xlabel('Frame')\n",
    "ax4.legend()\n",
    "ax4.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Outlier Detection and Removal\n",
    "\n",
    "Detect and handle outliers in ball position data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple outlier detection using velocity-based approach\n",
    "def detect_velocity_outliers(df, position_col, threshold_multiplier=3):\n",
    "    \"\"\"\n",
    "    Detect outliers based on sudden velocity changes\n",
    "    \"\"\"\n",
    "    # Calculate velocity (change in position)\n",
    "    velocity = df[position_col].diff().abs()\n",
    "    \n",
    "    # Define threshold as mean + threshold_multiplier * std\n",
    "    threshold = velocity.mean() + threshold_multiplier * velocity.std()\n",
    "    \n",
    "    # Mark outliers\n",
    "    outliers = velocity > threshold\n",
    "    \n",
    "    return outliers, threshold\n",
    "\n",
    "# Detect outliers in X and Y coordinates\n",
    "outliers_x, threshold_x = detect_velocity_outliers(df_ball_interpolated, 'center_x')\n",
    "outliers_y, threshold_y = detect_velocity_outliers(df_ball_interpolated, 'center_y')\n",
    "\n",
    "# Combine outliers\n",
    "outliers_combined = outliers_x | outliers_y\n",
    "\n",
    "print(f\"Detected {outliers_combined.sum()} outliers ({outliers_combined.sum()/len(df_ball_interpolated):.2%})\")\n",
    "print(f\"X velocity threshold: {threshold_x:.2f} pixels/frame\")\n",
    "print(f\"Y velocity threshold: {threshold_y:.2f} pixels/frame\")\n",
    "\n",
    "# Create cleaned dataset\n",
    "df_ball_cleaned = df_ball_interpolated.copy()\n",
    "df_ball_cleaned.loc[outliers_combined, ['center_x', 'center_y']] = np.nan\n",
    "df_ball_cleaned = df_ball_cleaned.interpolate(method='linear')\n",
    "\n",
    "print(\"\\nOutliers removed and re-interpolated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Quality Metrics\n",
    "\n",
    "Calculate metrics to assess preprocessing quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate preprocessing quality metrics\n",
    "def calculate_smoothness(data):\n",
    "    \"\"\"Calculate data smoothness using second derivative\"\"\"\n",
    "    second_derivative = np.diff(data, n=2)\n",
    "    return np.std(second_derivative)\n",
    "\n",
    "# Compare smoothness before and after preprocessing\n",
    "raw_smoothness_x = calculate_smoothness(df_ball_interpolated['center_x'].dropna())\n",
    "filtered_smoothness_x = calculate_smoothness(df_ball_smoothed['center_x_lowpass'])\n",
    "\n",
    "raw_smoothness_y = calculate_smoothness(df_ball_interpolated['center_y'].dropna())\n",
    "filtered_smoothness_y = calculate_smoothness(df_ball_smoothed['center_y_lowpass'])\n",
    "\n",
    "print(\"Data Quality Metrics:\")\n",
    "print(f\"X Coordinate Smoothness:\")\n",
    "print(f\"  Raw (interpolated): {raw_smoothness_x:.2f}\")\n",
    "print(f\"  After filtering: {filtered_smoothness_x:.2f}\")\n",
    "print(f\"  Improvement: {(raw_smoothness_x - filtered_smoothness_x)/raw_smoothness_x:.2%}\")\n",
    "print(f\"\\nY Coordinate Smoothness:\")\n",
    "print(f\"  Raw (interpolated): {raw_smoothness_y:.2f}\")\n",
    "print(f\"  After filtering: {filtered_smoothness_y:.2f}\")\n",
    "print(f\"  Improvement: {(raw_smoothness_y - filtered_smoothness_y)/raw_smoothness_y:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Preprocessed Data\n",
    "\n",
    "Save the preprocessed data for use in subsequent chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final preprocessed dataset\n",
    "df_final = pd.DataFrame({\n",
    "    'frame': range(len(df_ball_smoothed)),\n",
    "    'center_x_raw': df_ball_interpolated['center_x'],\n",
    "    'center_y_raw': df_ball_interpolated['center_y'],\n",
    "    'center_x_smooth': df_ball_smoothed['center_x_smooth'],\n",
    "    'center_y_smooth': df_ball_smoothed['center_y_smooth'],\n",
    "    'center_x_filtered': df_ball_smoothed['center_x_lowpass'],\n",
    "    'center_y_filtered': df_ball_smoothed['center_y_lowpass'],\n",
    "    'width': df_ball_interpolated['width'],\n",
    "    'height': df_ball_interpolated['height']\n",
    "})\n",
    "\n",
    "# Save preprocessed data\n",
    "df_final.to_csv('ball_positions_preprocessed.csv', index=False)\n",
    "print(\"Preprocessed data saved to 'ball_positions_preprocessed.csv'\")\n",
    "print(f\"Final dataset shape: {df_final.shape}\")\n",
    "print(\"\\nFinal dataset summary:\")\n",
    "print(df_final.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated Chapter 3 concepts:\n",
    "\n",
    "1. **Missing Value Imputation**: Used pandas interpolation to fill gaps in ball detection data\n",
    "2. **Rolling Mean Smoothing**: Applied window-based smoothing equivalent to low-pass filtering\n",
    "3. **Butterworth Low-Pass Filter**: Implemented actual frequency-domain filtering\n",
    "4. **Coordinate Transformations**: Converted bounding boxes to center coordinates\n",
    "5. **Data Normalization**: Scaled coordinates to normalized ranges\n",
    "6. **Outlier Detection**: Identified and removed velocity-based outliers\n",
    "7. **Quality Assessment**: Measured preprocessing effectiveness\n",
    "\n",
    "The preprocessed ball position data is now ready for feature extraction and analysis in subsequent chapters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}